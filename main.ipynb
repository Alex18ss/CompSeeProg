{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-20T11:54:45.657461Z",
     "start_time": "2025-11-20T11:54:44.820677Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T11:57:09.195139Z",
     "start_time": "2025-11-20T11:57:09.065798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === МОДЕЛИ ПОЛА И ВОЗРАСТА ===\n",
    "GENDER_PROTO = \"models/gender_deploy.prototxt\"\n",
    "GENDER_MODEL = \"models/gender_net.caffemodel\"\n",
    "\n",
    "AGE_PROTO = \"models/age_deploy.prototxt\"\n",
    "AGE_MODEL = \"models/age_net.caffemodel\"\n",
    "\n",
    "gender_net = cv2.dnn.readNetFromCaffe(GENDER_PROTO, GENDER_MODEL)\n",
    "age_net = cv2.dnn.readNetFromCaffe(AGE_PROTO, AGE_MODEL)\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263, 87.7689, 114.8958)\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "AGE_BUCKETS = [\n",
    "    '(0-2)', '(4-6)', '(8-12)', '(15-20)',\n",
    "    '(25-32)', '(38-43)', '(48-53)', '(60-80)', '(80-100)'\n",
    "]\n",
    "\n",
    "# === MEDIAPIPE ===\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_face_detection = mp.solutions.face_detection"
   ],
   "id": "ae18503adca710c2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T11:57:11.079185Z",
     "start_time": "2025-11-20T11:57:11.074822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_label(frame, landmarks, landmark_enum, label_text: str,\n",
    "               visibility_thr: float, img_w: int, img_h: int,\n",
    "               point_in_face_func):\n",
    "    \"\"\"\n",
    "    Подписываем сустав, если он видим и не попадает в прямоугольник лица.\n",
    "    \"\"\"\n",
    "    lm = landmarks[landmark_enum.value]\n",
    "    if lm.visibility < visibility_thr:\n",
    "        return\n",
    "\n",
    "    x = int(lm.x * img_w)\n",
    "    y = int(lm.y * img_h)\n",
    "\n",
    "    if point_in_face_func(x, y):\n",
    "        return\n",
    "\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        label_text,\n",
    "        (x + 5, y - 5),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (255, 255, 0),\n",
    "        1,\n",
    "        cv2.LINE_AA\n",
    "    )\n"
   ],
   "id": "d9a3574a049abb1b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9cfb7fbf1fc9d37f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T11:57:17.579201Z",
     "start_time": "2025-11-20T11:57:13.301829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# === КАМЕРА === #\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Камера не открылась. Проверь доступ к камере.\")\n",
    "    raise SystemExit\n",
    "\n",
    "with mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=0.7,\n",
    "        min_tracking_confidence=0.7) as pose, \\\n",
    "        mp_face_detection.FaceDetection(\n",
    "            model_selection=0,  # 0 — ближние лица\n",
    "            min_detection_confidence=0.7\n",
    "        ) as face_det:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # Перевод в RGB (нужно и для pose, и для face)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # -------- ЛИЦО (mediapipe) --------\n",
    "        faces = []\n",
    "        face_results = face_det.process(image_rgb)\n",
    "        if face_results.detections:\n",
    "            for det in face_results.detections:\n",
    "                bbox = det.location_data.relative_bounding_box\n",
    "                x1 = int(bbox.xmin * w)\n",
    "                y1 = int(bbox.ymin * h)\n",
    "                x2 = int((bbox.xmin + bbox.width) * w)\n",
    "                y2 = int((bbox.ymin + bbox.height) * h)\n",
    "\n",
    "                # ограничиваем внутри кадра\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "                x2 = min(w - 1, x2)\n",
    "                y2 = min(h - 1, y2)\n",
    "\n",
    "                if x2 > x1 and y2 > y1:\n",
    "                    faces.append((x1, y1, x2, y2))\n",
    "\n",
    "\n",
    "        # функция: точка попадает внутрь какого-либо лица?\n",
    "        def point_in_face(xp, yp) -> bool:\n",
    "            for (fx1, fy1, fx2, fy2) in faces:\n",
    "                if fx1 <= xp <= fx2 and fy1 <= yp <= fy2:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "\n",
    "        # -------- ПОЗА (скелет) --------\n",
    "        result = pose.process(image_rgb)\n",
    "\n",
    "        if result.pose_landmarks:\n",
    "            landmarks = result.pose_landmarks.landmark\n",
    "            visibility_thr = 0.7  # фильтр по видимости точки\n",
    "\n",
    "            # Рисуем кости вручную, пропуская те, что заходят в область лица\n",
    "            for connection in mp_pose.POSE_CONNECTIONS:\n",
    "                start_idx = connection[0]\n",
    "                end_idx = connection[1]\n",
    "\n",
    "                lm_start = landmarks[start_idx]\n",
    "                lm_end = landmarks[end_idx]\n",
    "\n",
    "                if lm_start.visibility < visibility_thr or lm_end.visibility < visibility_thr:\n",
    "                    continue\n",
    "\n",
    "                x1 = int(lm_start.x * w)\n",
    "                y1 = int(lm_start.y * h)\n",
    "                x2 = int(lm_end.x * w)\n",
    "                y2 = int(lm_end.y * h)\n",
    "\n",
    "                # Если хотя бы одна точка кости в области лица — не рисуем\n",
    "                if point_in_face(x1, y1) or point_in_face(x2, y2):\n",
    "                    continue\n",
    "\n",
    "                cv2.line(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "\n",
    "            # Подписи суставов (тоже с учётом лица)\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
    "                       \"Left shoulder\", visibility_thr, w, h, point_in_face)\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "                       \"Right shoulder\", visibility_thr, w, h, point_in_face)\n",
    "\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.LEFT_ELBOW,\n",
    "                       \"Left elbow\", visibility_thr, w, h, point_in_face)\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.RIGHT_ELBOW,\n",
    "                       \"Right elbow\", visibility_thr, w, h, point_in_face)\n",
    "\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.LEFT_WRIST,\n",
    "                       \"Left hand\", visibility_thr, w, h, point_in_face)\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.RIGHT_WRIST,\n",
    "                       \"Right hand\", visibility_thr, w, h, point_in_face)\n",
    "\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "                       \"Left knee\", visibility_thr, w, h, point_in_face)\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "                       \"Right knee\", visibility_thr, w, h, point_in_face)\n",
    "\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "                       \"Left leg\", visibility_thr, w, h, point_in_face)\n",
    "            draw_label(frame, landmarks, mp_pose.PoseLandmark.RIGHT_ANKLE,\n",
    "                       \"Right leg\", visibility_thr, w, h, point_in_face)\n",
    "\n",
    "        # -------- ЛИЦО + ПОЛ + ВОЗРАСТ (через Caffe) --------\n",
    "        for (x1, y1, x2, y2) in faces:\n",
    "            face_crop = frame[y1:y2, x1:x2]\n",
    "            if face_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                face_crop,\n",
    "                1.0,\n",
    "                (227, 227),\n",
    "                MODEL_MEAN_VALUES,\n",
    "                swapRB=False\n",
    "            )\n",
    "\n",
    "            # пол\n",
    "            gender_net.setInput(blob)\n",
    "            gPreds = gender_net.forward()\n",
    "            gender = GENDER_LIST[np.argmax(gPreds[0])]\n",
    "            g_conf = float(np.max(gPreds[0]))\n",
    "\n",
    "            # возраст\n",
    "            age_net.setInput(blob)\n",
    "            aPreds = age_net.forward()\n",
    "            age = AGE_BUCKETS[np.argmax(aPreds[0])]\n",
    "            a_conf = float(np.max(aPreds[0]))\n",
    "\n",
    "            # рамка и подпись\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"{gender} {g_conf:.2f}, {age} {a_conf:.2f}\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7,\n",
    "                (0, 255, 0),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Pose + Face + Gender + Age\", frame)\n",
    "\n",
    "        # выход по 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "b2deb3b38fc78f3d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763639834.466901 2066645 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4\n",
      "I0000 00:00:1763639834.472523 2066645 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M4\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1763639834.489700 2074516 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/Users/alexhoudini/PycharmProjects/pizda/.venv/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "W0000 00:00:1763639834.563793 2074501 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1763639834.577312 2074507 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
